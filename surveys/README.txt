Framing Survey:
Completed Nov 2019

Respondents were asked to rate the fairness of four hand-picked features from the bail, unemployment, hospital, and loan domains. The fairness of each feature is rated as either 'Very Unfair', 'Unfair', 'Somewhat Unfair', 'Neutral', 'Somewhat Fair', 'Fair', or 'Very Fair'.

Mentioned - the terms 'Machine Learning Computer Program' were explicitly mentioned and the question framed as if computers are aiding in the decision making process.
NotMentioned - No mention of machine learning or computers is made and the question is framed as if humans are making the decisions.


Nec/Suf Survey:
Completed Jan-Feb 2020

Respondents were given the description for their (randomly assigned) domain, and then were asked to rate the fairness of each feature and explain why by checking any of the eight properties or filling in their own.

QOrder - respondents were assigned one of two random feature orders.


Main Survey:
Completed March-May 2020

Respondents were given the description for their domain, asked to rate the fairness of each feature, and asked to rate how much they agree that the features hold each property.


Accuracy (aka 'Replaced') and No Relevance (aka 'Removed') Surveys:
Completed May-June 2020

Identical to the main survey, however the Accuracy survey replaced the feature 'Relevance' with 'Accuracy' and the No Relevance survey completely removed 'Relevance' as an option.


See data folder for more information and results.
